{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:29.508613Z",
     "start_time": "2025-11-28T11:43:29.049730Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1a056efbd33fb67d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:29.516255Z",
     "start_time": "2025-11-28T11:43:29.513190Z"
    }
   },
   "source": [
    "# ---------- Konfiguration (anpassen falls nötig) ----------\n",
    "TARGET_COMPANIES = [\n",
    "    {\"name\": \"NVIDIA\", \"ticker\": \"NVDA\"},\n",
    "    {\"name\": \"Tesla\", \"ticker\": \"TSLA\"},\n",
    "    {\"name\": \"ASML Holdings\", \"ticker\": \"ASML\"},\n",
    "    {\"name\": \"META\", \"ticker\": \"META\"},\n",
    "    {\"name\": \"Amazon\", \"ticker\": \"AMZN\"},\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "4b3602878b9ada48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:29.853316Z",
     "start_time": "2025-11-28T11:43:29.850053Z"
    }
   },
   "source": [
    "# Falls für bestimmte Märkte ein Exchange-Suffix nötig ist, passe hier an.\n",
    "# Beispiel: ASML an Euronext (wenn erforderlich) -> 'ASML.AS'\n",
    "SYMBOL_OVERRIDES = {\n",
    "    # 'ASML': 'ASML.AS',\n",
    "}\n",
    "\n",
    "MONTHS_BACK = 6\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR', '/mnt/data')\n",
    "FINNHUB_API_KEY = os.getenv('FINNHUB_API_KEY') or None"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "daff468315f5b8e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:29.864979Z",
     "start_time": "2025-11-28T11:43:29.857591Z"
    }
   },
   "source": [
    "# ---------------------------------------------------------\n",
    "\n",
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    try:\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    except Exception:\n",
    "        # Fallback auf pwd\n",
    "        OUTPUT_DIR = os.getcwd()\n",
    "\n",
    "# Helper: unix timestamp for a datetime.date or datetime\n",
    "def to_unix_ts(dt: datetime) -> int:\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "# Berechne from/to Unix für 'months_back' Monate bis heute\n",
    "def timeframe_months_back(months_back: int = 6):\n",
    "    to_dt = datetime.utcnow().date()\n",
    "    # Pandas DateOffset ist praktisch für Monatsberechnung\n",
    "    from_dt = (pd.to_datetime(to_dt) - pd.DateOffset(months=months_back)).date()\n",
    "    # vom 00:00:00 UTC des from_dt bis 23:59:59 UTC des to_dt\n",
    "    from_ts = int(pd.to_datetime(from_dt).replace(tzinfo=timezone.utc).timestamp())\n",
    "    to_ts = int(pd.to_datetime(to_dt).replace(tzinfo=timezone.utc).timestamp())\n",
    "    return from_ts, to_ts\n",
    "\n",
    "\n",
    "# Robustes Fetch für Finnhub /stock/candle\n",
    "def fetch_daily_ohlcv(symbol: str, months_back: int = 1, max_retries: int = 5, pause_between_retries: float = 1.0) -> pd.DataFrame:\n",
    "    base_url = \"https://finnhub.io/api/v1/stock/candle\"\n",
    "    from_ts, to_ts = timeframe_months_back(months_back)\n",
    "\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"resolution\": \"D\",\n",
    "        \"from\": from_ts,\n",
    "        \"to\": to_ts,\n",
    "        \"token\": FINNHUB_API_KEY,\n",
    "    }\n",
    "\n",
    "    # Retry-Loop mit exponentiellem Backoff\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(base_url, params=params, timeout=20)\n",
    "        except Exception as e:\n",
    "            print(f\"Request error for {symbol} (attempt {attempt}): {e}\")\n",
    "            time.sleep(pause_between_retries * attempt)\n",
    "            continue\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            # Finnhub: data['s'] == 'ok' oder 'no_data'\n",
    "            if data.get('s') == 'ok':\n",
    "                df = pd.DataFrame({\n",
    "                    'date': pd.to_datetime(data['t'], unit='s', utc=True),\n",
    "                    'open': data.get('o', []),\n",
    "                    'high': data.get('h', []),\n",
    "                    'low': data.get('l', []),\n",
    "                    'close': data.get('c', []),\n",
    "                    'volume': data.get('v', []),\n",
    "                })\n",
    "                return df\n",
    "            else:\n",
    "                # 'no_data' oder anderes\n",
    "                print(f\"No data for {symbol} in timeframe (Finnhub response s={data.get('s')}).\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "        elif resp.status_code in (429, 503):\n",
    "            # Rate limited / service unavailable -> wait & retry\n",
    "            wait = pause_between_retries * attempt\n",
    "            print(f\"Rate-limited or service unavailable for {symbol} (status {resp.status_code}). Sleeping {wait}s and retrying...\")\n",
    "            time.sleep(wait)\n",
    "            continue\n",
    "        else:\n",
    "            # andere Fehler -> log und abbrechen\n",
    "            try:\n",
    "                txt = resp.text[:400]\n",
    "            except Exception:\n",
    "                txt = '<no response body>'\n",
    "            print(f\"Error fetching {symbol}: status {resp.status_code} - {txt}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    print(f\"Failed to fetch {symbol} after {max_retries} attempts.\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Speichert DataFrame als CSV und JSON (records)\n",
    "def save_outputs(df: pd.DataFrame, ticker: str, out_dir: str = OUTPUT_DIR, months_back: int = MONTHS_BACK):\n",
    "    if df.empty:\n",
    "        print(f\"No data to save for {ticker}.\")\n",
    "        return None\n",
    "\n",
    "    csv_path = os.path.join(out_dir, f\"{ticker}_daily_{months_back}mo.csv\")\n",
    "    json_path = os.path.join(out_dir, f\"{ticker}_daily_{months_back}mo.json\")\n",
    "\n",
    "    # Normalize date to ISO string (naive) for JSON\n",
    "    df_to_save = df.copy()\n",
    "    df_to_save['date'] = df_to_save['date'].dt.tz_convert('UTC').dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    df_to_save.to_csv(csv_path, index=False)\n",
    "\n",
    "    # JSON as list of dicts\n",
    "    records = df_to_save.to_dict(orient='records')\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(df_to_save)} rows for {ticker}: {csv_path}, {json_path}\")\n",
    "    return csv_path, json_path\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "5e4ca93bc3d3ad03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:33.737202Z",
     "start_time": "2025-11-28T11:43:29.871513Z"
    }
   },
   "source": [
    "# ---------- Main: Fetch & Save für alle TARGET_COMPANIES ----------\n",
    "\n",
    "def main():\n",
    "    global FINNHUB_API_KEY\n",
    "    if not FINNHUB_API_KEY:\n",
    "        # Interaktives Fallback (nur, wenn keine Env gesetzt ist)\n",
    "        FINNHUB_API_KEY = input(\n",
    "            'FINNHUB_API_KEY nicht gefunden. Bitte API-Key eingeben (oder ENTER zum Abbrechen): ').strip() or None\n",
    "        if not FINNHUB_API_KEY:\n",
    "            print('Kein API-Key. Abbruch.')\n",
    "            return\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for comp in tqdm(TARGET_COMPANIES, desc='Fetching tickers'):\n",
    "        ticker = comp['ticker']\n",
    "        symbol = SYMBOL_OVERRIDES.get(ticker, ticker)\n",
    "        print(f\"\\nFetching {comp['name']} ({ticker}) -> symbol used: {symbol}\")\n",
    "\n",
    "        df = fetch_daily_ohlcv(symbol, months_back=MONTHS_BACK)\n",
    "        if df.empty:\n",
    "            print(f\"Kein DataFrame für {ticker}. Überspringe.\")\n",
    "            continue\n",
    "\n",
    "        # Markiere symbol/ticker\n",
    "        df['symbol'] = ticker\n",
    "        all_dfs.append(df)\n",
    "\n",
    "        # Save per-ticker\n",
    "        save_outputs(df, ticker, out_dir=OUTPUT_DIR, months_back=MONTHS_BACK)\n",
    "\n",
    "        # Kleiner sleep um Rate-Limits zu schonen\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Kombiniertes Save\n",
    "    if all_dfs:\n",
    "        df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "        # Sortieren\n",
    "        df_all = df_all.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "        combined_csv = os.path.join(OUTPUT_DIR, f\"combined_daily_{MONTHS_BACK}mo.csv\")\n",
    "        combined_json = os.path.join(OUTPUT_DIR, f\"combined_daily_{MONTHS_BACK}mo.json\")\n",
    "\n",
    "        df_all_to_save = df_all.copy()\n",
    "        df_all_to_save['date'] = df_all_to_save['date'].dt.tz_convert('UTC').dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        df_all_to_save.to_csv(combined_csv, index=False)\n",
    "        with open(combined_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(df_all_to_save.to_dict(orient='records'), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"\\nSaved combined data: {combined_csv}, {combined_json}\")\n",
    "    else:\n",
    "        print('Keine Daten gesamthaft geladen.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching tickers:   0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\18284\\AppData\\Local\\Temp\\ipykernel_12080\\3950371143.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  to_dt = datetime.utcnow().date()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching NVIDIA (NVDA) -> symbol used: NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching tickers:  20%|██        | 1/5 [00:00<00:01,  3.21it/s]C:\\Users\\18284\\AppData\\Local\\Temp\\ipykernel_12080\\3950371143.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  to_dt = datetime.utcnow().date()\n",
      "Fetching tickers:  40%|████      | 2/5 [00:00<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching NVDA: status 403 - {\"error\":\"You don't have access to this resource.\"}\n",
      "Kein DataFrame für NVDA. Überspringe.\n",
      "\n",
      "Fetching Tesla (TSLA) -> symbol used: TSLA\n",
      "Error fetching TSLA: status 403 - {\"error\":\"You don't have access to this resource.\"}\n",
      "Kein DataFrame für TSLA. Überspringe.\n",
      "\n",
      "Fetching ASML Holdings (ASML) -> symbol used: ASML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18284\\AppData\\Local\\Temp\\ipykernel_12080\\3950371143.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  to_dt = datetime.utcnow().date()\n",
      "Fetching tickers:  60%|██████    | 3/5 [00:00<00:00,  4.62it/s]C:\\Users\\18284\\AppData\\Local\\Temp\\ipykernel_12080\\3950371143.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  to_dt = datetime.utcnow().date()\n",
      "Fetching tickers:  80%|████████  | 4/5 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching ASML: status 403 - {\"error\":\"You don't have access to this resource.\"}\n",
      "Kein DataFrame für ASML. Überspringe.\n",
      "\n",
      "Fetching META (META) -> symbol used: META\n",
      "Error fetching META: status 403 - {\"error\":\"You don't have access to this resource.\"}\n",
      "Kein DataFrame für META. Überspringe.\n",
      "\n",
      "Fetching Amazon (AMZN) -> symbol used: AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18284\\AppData\\Local\\Temp\\ipykernel_12080\\3950371143.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  to_dt = datetime.utcnow().date()\n",
      "Fetching tickers: 100%|██████████| 5/5 [00:01<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching AMZN: status 403 - {\"error\":\"You don't have access to this resource.\"}\n",
      "Kein DataFrame für AMZN. Überspringe.\n",
      "Keine Daten gesamthaft geladen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "b505952082e69c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:33.747237Z",
     "start_time": "2025-11-28T11:43:33.745060Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a1393c99bf6fe7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:33.759383Z",
     "start_time": "2025-11-28T11:43:33.757487Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca196478edfa10fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:33.772344Z",
     "start_time": "2025-11-28T11:43:33.770543Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b00b4ed7238857d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:43:33.792368Z",
     "start_time": "2025-11-28T11:43:33.790680Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_agentic_ai",
   "language": "python",
   "name": "agentic_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
