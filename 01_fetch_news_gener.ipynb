{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3283bfc6aed41591",
   "metadata": {},
   "source": [
    "\n",
    "# 01_fetch_news.ipynb — News sammeln (Finnhub + NewsAPI)\n",
    "\n",
    "Dieses Notebook sammelt Nachrichten für eine Auswahl von Zielunternehmen (Tickern), kombiniert Finnhub Company-News und NewsAPI-Keyword-Suche und speichert die Rohdaten in `agent_new/data/raw_news.csv`.\n",
    "\n",
    "**Wichtig:** Setze die Umgebungsvariablen `FINNHUB_API_KEY` und `NEWS_API_KEY` bevor du ausführst."
   ]
  },
  {
   "cell_type": "code",
   "id": "1792edd7151fcd89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:14:41.275794Z",
     "start_time": "2025-12-17T15:14:41.259937Z"
    }
   },
   "source": [
    "# =========================================================hhhhhh\n",
    "# 0. Imports & Setup\n",
    "# =========================================================\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "dd4bc233c2ec9400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:14:42.859279Z",
     "start_time": "2025-12-17T15:14:42.843439Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# 1. 基础环境\n",
    "# =========================================================\n",
    "os.makedirs(\"Tools/data\", exist_ok=True)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys（你现在是直接写死的，我保持不动）\n",
    "FINNHUB_API_KEY = \"d4m6udpr01qjidhtuevgd4m6udpr01qjidhtuf00\"\n",
    "NEWS_API_KEY = \"pub_97d3b41e381a468393a42810d780d265\"\n",
    "GEMINI_API_KEY = \"AIzaSyDHRIpGIwaXjNFsUouUJf8r64AeRm18mBA\"\n",
    "\n",
    "if not FINNHUB_API_KEY:\n",
    "    print(\"WARNUNG: FINNHUB_API_KEY fehlt\")\n",
    "if not NEWS_API_KEY:\n",
    "    print(\"WARNUNG: NEWS_API_KEY fehlt\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "82467a5ff2ba6500",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# 2. 输出目录（保持你原来的）\n",
    "# =========================================================\n",
    "BASE_DATA_DIR = os.path.join(\"../../../../to delete/aai_final\", \"Tools\", \"data\")\n",
    "OUT_DIR_01 = os.path.join(BASE_DATA_DIR, \"01\")\n",
    "os.makedirs(OUT_DIR_01, exist_ok=True)\n",
    "\n",
    "print(\"01 output dir:\", os.path.abspath(OUT_DIR_01))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:16:15.330068Z",
     "start_time": "2025-12-17T15:15:57.610338Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install yfinance\n",
   "id": "7a25480dc9eea20c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.4/123.4 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting protobuf>=3.19.0\n",
      "  Downloading protobuf-6.33.2-cp39-cp39-win_amd64.whl (436 kB)\n",
      "     ------------------------------------- 436.9/436.9 kB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from yfinance) (2.5.2)\n",
      "Collecting requests>=2.31\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.7/64.7 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2022.5\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     -------------------------------------- 509.2/509.2 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from yfinance) (4.11.1)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from yfinance) (1.21.5)\n",
      "Collecting websockets>=13.0\n",
      "  Downloading websockets-15.0.1-cp39-cp39-win_amd64.whl (176 kB)\n",
      "     -------------------------------------- 176.8/176.8 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.4.7-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Collecting peewee>=3.16.2\n",
      "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 11.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from yfinance) (1.4.4)\n",
      "Collecting curl_cffi>=0.7\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 17.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.15.1)\n",
      "Collecting certifi>=2024.2.2\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "     -------------------------------------- 159.4/159.4 kB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.11)\n",
      "Requirement already satisfied: pycparser in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\18284\\anaconda3_3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Building wheels for collected packages: multitasking, peewee\n",
      "  Building wheel for multitasking (setup.py): started\n",
      "  Building wheel for multitasking (setup.py): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15549 sha256=5231291759923f3b6129a1dbcdbde5ff9dee7240c5d54eb45079087fe4a9c48d\n",
      "  Stored in directory: c:\\users\\18284\\appdata\\local\\pip\\cache\\wheels\\98\\75\\bc\\9eaa3cdeaaca347bab26c7e83a7e2f365d82584d65a2d48e7a\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.3-py3-none-any.whl size=139181 sha256=6a697bd5a036375a8bcbf8516a77dead1e5602fb63e6a43b61a585ee708c2eb6\n",
      "  Stored in directory: c:\\users\\18284\\appdata\\local\\pip\\cache\\wheels\\13\\f4\\97\\0867d369d6c1f69e8cf99dfe564bb05796822eb6709ee1f903\n",
      "Successfully built multitasking peewee\n",
      "Installing collected packages: pytz, peewee, multitasking, websockets, protobuf, frozendict, certifi, requests, curl_cffi, yfinance\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.1\n",
      "    Uninstalling pytz-2022.1:\n",
      "      Successfully uninstalled pytz-2022.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.9.14\n",
      "    Uninstalling certifi-2022.9.14:\n",
      "      Successfully uninstalled certifi-2022.9.14\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed certifi-2025.11.12 curl_cffi-0.13.0 frozendict-2.4.7 multitasking-0.0.12 peewee-3.18.3 protobuf-6.33.2 pytz-2025.2 requests-2.32.5 websockets-15.0.1 yfinance-0.2.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.32.5 which is incompatible.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "de02bfb939ffa730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:17:52.117588Z",
     "start_time": "2025-12-17T15:17:51.570381Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def load_sp500_tickers():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/116.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()  # 确认请求成功\n",
    "    # pandas 解析 HTML 表格\n",
    "    tables = pd.read_html(resp.text)\n",
    "    # Wikipedia 的第一个表格就是 S&P500 成分股\n",
    "    return tables[0][\"Symbol\"].tolist()\n",
    "\n",
    "ALL_TICKERS = load_sp500_tickers()\n",
    "\n",
    "UNIVERSE_SIZE = 20\n",
    "TARGET_COMPANIES = [{\"name\": t, \"ticker\": t} for t in ALL_TICKERS[:UNIVERSE_SIZE]]\n",
    "\n",
    "print(f\"Target companies: {len(TARGET_COMPANIES)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target companies: 20\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "c32af69e4153d30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:17:56.309626Z",
     "start_time": "2025-12-17T15:17:56.293514Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# 4. ★ 自动关键词生成（替代 COMPANY_KEYWORDS）\n",
    "# =========================================================\n",
    "def keywords_for_ticker(ticker: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    最小可扩展方案：\n",
    "    - 不手写 dict\n",
    "    - 后续 relevance 会过滤噪音\n",
    "    \"\"\"\n",
    "    return [ticker]"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "ed266112a94b0fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:17:59.001905Z",
     "start_time": "2025-12-17T15:17:58.986224Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# 5. 时间工具函数\n",
    "# =========================================================\n",
    "def utc_now() -> datetime:\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "def cutoff_months_ago(months: int = 6) -> datetime:\n",
    "    return utc_now() - timedelta(days=30 * months)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a475f2b450a3693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:18:20.104303Z",
     "start_time": "2025-12-17T15:18:20.092330Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# 6. Finnhub 公司新闻\n",
    "# =========================================================\n",
    "def fetch_finnhub_company_news(\n",
    "    symbol: str,\n",
    "    months_back: int = 6,\n",
    "    max_items: int = 200\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    if not FINNHUB_API_KEY:\n",
    "        return []\n",
    "\n",
    "    url = \"https://finnhub.io/api/v1/company-news\"\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"from\": cutoff_months_ago(months_back).date().isoformat(),\n",
    "        \"to\": utc_now().date().isoformat(),\n",
    "        \"token\": FINNHUB_API_KEY\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, timeout=15)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[Finnhub] Fehler für {symbol}: {e}\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for item in data[:max_items]:\n",
    "        ts = item.get(\"datetime\")\n",
    "        pub_iso = (\n",
    "            datetime.utcfromtimestamp(ts).isoformat() + \"Z\"\n",
    "            if isinstance(ts, (int, float))\n",
    "            else None\n",
    "        )\n",
    "        results.append({\n",
    "            \"provider\": \"finnhub\",\n",
    "            \"ticker\": symbol,\n",
    "            \"title\": item.get(\"headline\") or item.get(\"summary\"),\n",
    "            \"summary\": item.get(\"summary\"),\n",
    "            \"url\": item.get(\"url\"),\n",
    "            \"image\": item.get(\"image\"),\n",
    "            \"source\": item.get(\"source\"),\n",
    "            \"published_at_utc\": pub_iso,\n",
    "            \"collected_at_utc\": utc_now().isoformat()\n",
    "        })\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "ba1d82a0c338cbca",
   "metadata": {},
   "source": [
    "**Hinweise:** Teste zuerst mit wenigen Artikeln (max_per_keyword klein). API-Keys müssen gesetzt sein. Die Ausgabe: `agent_new/data/raw_news.csv`.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:18:23.779482Z",
     "start_time": "2025-12-17T15:18:23.769559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 7. NewsAPI 关键词新闻\n",
    "# =========================================================\n",
    "def fetch_newsapi_for_keyword(\n",
    "    keyword: str,\n",
    "    months_back: int = 1,\n",
    "    max_items: int = 50\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    if not NEWS_API_KEY:\n",
    "        return []\n",
    "\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    from_date = cutoff_months_ago(1).date().isoformat()  # free tier 限制\n",
    "\n",
    "    params = {\n",
    "        \"q\": keyword,\n",
    "        \"language\": \"en\",\n",
    "        \"from\": from_date,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"pageSize\": max_items,\n",
    "        \"apiKey\": NEWS_API_KEY,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(base_url, params=params, timeout=15)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[NewsAPI] Fehler für {keyword}: {e}\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for art in data.get(\"articles\", []):\n",
    "        src = art.get(\"source\") or {}\n",
    "        results.append({\n",
    "            \"provider\": \"newsapi\",\n",
    "            \"ticker\": None,\n",
    "            \"title\": art.get(\"title\"),\n",
    "            \"summary\": art.get(\"description\") or art.get(\"content\"),\n",
    "            \"url\": art.get(\"url\"),\n",
    "            \"image\": art.get(\"urlToImage\"),\n",
    "            \"source\": src.get(\"name\"),\n",
    "            \"published_at_utc\": art.get(\"publishedAt\"),\n",
    "            \"collected_at_utc\": utc_now().isoformat()\n",
    "        })\n",
    "\n",
    "    return results"
   ],
   "id": "e115838ea0273fb0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:18:27.560344Z",
     "start_time": "2025-12-17T15:18:27.544191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 8. ★ 核心收集函数\n",
    "# =========================================================\n",
    "def collect_all_news(\n",
    "    months_back: int = 6,\n",
    "    max_per_keyword: int = 20\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for comp in tqdm(TARGET_COMPANIES):\n",
    "        ticker = comp[\"ticker\"]\n",
    "\n",
    "        # Finnhub\n",
    "        fh_news = fetch_finnhub_company_news(\n",
    "            ticker,\n",
    "            months_back=months_back,\n",
    "            max_items=max_per_keyword\n",
    "        )\n",
    "        all_rows.extend(fh_news)\n",
    "\n",
    "        # NewsAPI\n",
    "        for kw in keywords_for_ticker(ticker):\n",
    "            na_news = fetch_newsapi_for_keyword(\n",
    "                kw,\n",
    "                months_back=months_back,\n",
    "                max_items=max_per_keyword\n",
    "            )\n",
    "            for item in na_news:\n",
    "                item[\"ticker\"] = ticker\n",
    "                all_rows.append(item)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR_01, \"raw_news.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(\"Gespeicherte Rohdaten:\", os.path.abspath(out_path))\n",
    "    return df\n"
   ],
   "id": "19350c1b7f3cc0cc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:18:48.115951Z",
     "start_time": "2025-12-17T15:18:38.180450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 9. Run（测试）\n",
    "# =========================================================\n",
    "df = collect_all_news(months_back=6, max_per_keyword=20)\n",
    "print(\"Gesammelte Artikel:\", len(df))\n",
    "df.head()"
   ],
   "id": "586a0bf570d8b230",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3457453d8f9c44c1aadd5c18e330dd65"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NewsAPI] Fehler für MMM: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=MMM&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für AOS: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=AOS&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ABT: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ABT&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ABBV: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ABBV&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ACN: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ACN&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ADBE: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ADBE&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für AMD: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=AMD&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für AES: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=AES&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für AFL: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=AFL&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für A: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=A&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für APD: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=APD&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ABNB: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ABNB&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für AKAM: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=AKAM&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ALB: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ALB&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ARE: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ARE&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ALGN: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ALGN&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ALLE: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ALLE&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für LNT: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=LNT&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für ALL: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=ALL&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "[NewsAPI] Fehler für GOOGL: 401 Client Error: Unauthorized for url: https://newsapi.org/v2/everything?q=GOOGL&language=en&from=2025-11-17&sortBy=publishedAt&pageSize=20&apiKey=pub_97d3b41e381a468393a42810d780d265\n",
      "Gespeicherte Rohdaten: C:\\to delete\\aai_final\\Tools\\data\\01\\raw_news.csv\n",
      "Gesammelte Artikel: 400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  provider ticker                                              title  \\\n",
       "0  finnhub    MMM  Jim Cramer Says “Industrials Always Work in Re...   \n",
       "1  finnhub    MMM  Barclays Maintains An Overweight Rating On 3M ...   \n",
       "2  finnhub    MMM              3M: Sales And Profits Are On The Rise   \n",
       "3  finnhub    MMM  3M: Operational Excellence And Turnaround Mome...   \n",
       "4  finnhub    MMM  How Recent Developments Are Rewriting the Stor...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  3M Company (NYSE:MMM) is one of the stocks Jim...   \n",
       "1  3M Company (NYSE:MMM) is among the 13 Best Nan...   \n",
       "2  3M gains with a 90% rebound, steady profits, n...   \n",
       "3  3M drives a turnaround with restructuring, Q3 ...   \n",
       "4  3M's fair value estimate has inched down to $1...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://finnhub.io/api/news?id=410a2b765b049f0...   \n",
       "1  https://finnhub.io/api/news?id=8623b9110d61064...   \n",
       "2  https://finnhub.io/api/news?id=0da7d2b2e6eb305...   \n",
       "3  https://finnhub.io/api/news?id=a2298ef5bc24c2b...   \n",
       "4  https://finnhub.io/api/news?id=e42ceee0cce24a1...   \n",
       "\n",
       "                                               image        source  \\\n",
       "0  https://s.yimg.com/rz/stage/p/yahoo_finance_en...         Yahoo   \n",
       "1  https://s.yimg.com/rz/stage/p/yahoo_finance_en...         Yahoo   \n",
       "2  https://static.seekingalpha.com/cdn/s3/uploads...  SeekingAlpha   \n",
       "3  https://static.seekingalpha.com/cdn/s3/uploads...  SeekingAlpha   \n",
       "4  https://s.yimg.com/rz/stage/p/yahoo_finance_en...         Yahoo   \n",
       "\n",
       "       published_at_utc                  collected_at_utc  \n",
       "0  2025-12-13T16:17:39Z  2025-12-17T15:18:38.537678+00:00  \n",
       "1  2025-12-12T13:49:02Z  2025-12-17T15:18:38.537678+00:00  \n",
       "2  2025-12-11T08:01:52Z  2025-12-17T15:18:38.537678+00:00  \n",
       "3  2025-12-11T02:07:33Z  2025-12-17T15:18:38.537678+00:00  \n",
       "4  2025-12-10T15:06:22Z  2025-12-17T15:18:38.537678+00:00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>image</th>\n",
       "      <th>source</th>\n",
       "      <th>published_at_utc</th>\n",
       "      <th>collected_at_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finnhub</td>\n",
       "      <td>MMM</td>\n",
       "      <td>Jim Cramer Says “Industrials Always Work in Re...</td>\n",
       "      <td>3M Company (NYSE:MMM) is one of the stocks Jim...</td>\n",
       "      <td>https://finnhub.io/api/news?id=410a2b765b049f0...</td>\n",
       "      <td>https://s.yimg.com/rz/stage/p/yahoo_finance_en...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>2025-12-13T16:17:39Z</td>\n",
       "      <td>2025-12-17T15:18:38.537678+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finnhub</td>\n",
       "      <td>MMM</td>\n",
       "      <td>Barclays Maintains An Overweight Rating On 3M ...</td>\n",
       "      <td>3M Company (NYSE:MMM) is among the 13 Best Nan...</td>\n",
       "      <td>https://finnhub.io/api/news?id=8623b9110d61064...</td>\n",
       "      <td>https://s.yimg.com/rz/stage/p/yahoo_finance_en...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>2025-12-12T13:49:02Z</td>\n",
       "      <td>2025-12-17T15:18:38.537678+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finnhub</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M: Sales And Profits Are On The Rise</td>\n",
       "      <td>3M gains with a 90% rebound, steady profits, n...</td>\n",
       "      <td>https://finnhub.io/api/news?id=0da7d2b2e6eb305...</td>\n",
       "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>2025-12-11T08:01:52Z</td>\n",
       "      <td>2025-12-17T15:18:38.537678+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finnhub</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M: Operational Excellence And Turnaround Mome...</td>\n",
       "      <td>3M drives a turnaround with restructuring, Q3 ...</td>\n",
       "      <td>https://finnhub.io/api/news?id=a2298ef5bc24c2b...</td>\n",
       "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>2025-12-11T02:07:33Z</td>\n",
       "      <td>2025-12-17T15:18:38.537678+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finnhub</td>\n",
       "      <td>MMM</td>\n",
       "      <td>How Recent Developments Are Rewriting the Stor...</td>\n",
       "      <td>3M's fair value estimate has inched down to $1...</td>\n",
       "      <td>https://finnhub.io/api/news?id=e42ceee0cce24a1...</td>\n",
       "      <td>https://s.yimg.com/rz/stage/p/yahoo_finance_en...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>2025-12-10T15:06:22Z</td>\n",
       "      <td>2025-12-17T15:18:38.537678+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3_3]",
   "language": "python",
   "name": "conda-env-anaconda3_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
