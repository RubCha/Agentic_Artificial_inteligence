{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 03_prioritize_news.ipynb — Priorisierung & Ranking\n",
    "\n",
    "Dieses Notebook liest die evaluierten News ein und berechnet einen Priorisierungs-Score (= wie wichtig ist die Nachricht für Handelsentscheidungen). Es kombiniert:\n",
    "- Relevanzscore (LLM)\n",
    "- Kategorie-Gewichte (company > policy > macro > geo > social)\n",
    "- optionaler Gemini-Aufruf zur Schätzung des kurzfristigen Markt-Impacts (falls gewünscht)\n",
    "\n",
    "Output: `agent_new/data/prioritized_news.csv`\n"
   ],
   "id": "794f0c3362903a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !pip install yfinance pandas google-genai\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EVAL_CSV = \"Tools/data/evaluated_news.csv\"\n",
    "if not os.path.exists(EVAL_CSV):\n",
    "    raise FileNotFoundError(f\"{EVAL_CSV} nicht gefunden. Führe 02_evaluate_relevance.ipynb aus.\")\n",
    "df = pd.read_csv(EVAL_CSV)\n",
    "print(\"Geladene Einträge:\", len(df))\n",
    "df.head()\n"
   ],
   "id": "46afaf989d727844"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env laden (optional, falls du auch eine .env Datei hast)\n",
    "load_dotenv()\n",
    "\n",
    "# API-Keys fest eingetragen\n",
    "FINNHUB_API_KEY = \"d4m6udpr01qjidhtuevgd4m6udpr01qjidhtuf00\"\n",
    "NEWS_API_KEY = \"pub_97d3b41e381a468393a42810d780d265\"\n",
    "GEMINI_API_KEY = \"AIzaSyDHRIpGIwaXjNFsUouUJf8r64AeRm18mBA\"\n",
    "\n",
    "# Optional: Warnungen, falls ein Key fehlt\n",
    "if not FINNHUB_API_KEY:\n",
    "    print(\"WARNUNG: FINNHUB_API_KEY nicht gefunden!\")\n",
    "if not NEWS_API_KEY:\n",
    "    print(\"WARNUNG: NEWS_API_KEY nicht gefunden!\")\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"WARNUNG: GEMINI_API_KEY nicht gefunden!\")\n",
    "\n",
    "# Default Einstellungen\n",
    "DEFAULT_LLM_PROVIDER = os.getenv(\"DEFAULT_LLM_PROVIDER\", \"gemini\")\n",
    "DEFAULT_TEMPERATURE = float(os.getenv(\"DEFAULT_TEMPERATURE\", 0.7))\n",
    "\n",
    "print(\"Keys geladen. LLM Provider:\", DEFAULT_LLM_PROVIDER, \"Temperatur:\", DEFAULT_TEMPERATURE)\n",
    "\n",
    "# Zelle 2 — Imports & Laden (ersetzt)\n",
    "# !pip install yfinance pandas google-genai\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE_DATA_DIR = os.path.join(\"../../../to delete/aai_final\", \"Tools\", \"data\")\n",
    "IN_DIR_02 = os.path.join(BASE_DATA_DIR, \"02\")\n",
    "OUT_DIR_03 = os.path.join(BASE_DATA_DIR, \"03\")\n",
    "os.makedirs(OUT_DIR_03, exist_ok=True)\n",
    "\n",
    "EVAL_CSV = os.path.join(IN_DIR_02, \"evaluated_news.csv\")\n",
    "if not os.path.exists(EVAL_CSV):\n",
    "    raise FileNotFoundError(f\"{EVAL_CSV} nicht gefunden. Führe 02_evaluate_relevance.ipynb aus (erzeugt evaluated_news.csv im /02-Ordner).\")\n",
    "\n",
    "df = pd.read_csv(EVAL_CSV)\n",
    "print(\"Geladene Einträge:\", len(df))\n",
    "print(\"Eingabe gelesen von:\", os.path.abspath(EVAL_CSV))\n",
    "print(\"03 output dir:\", os.path.abspath(OUT_DIR_03))\n",
    "df.head()\n",
    "\n"
   ],
   "id": "105ced8b306e75f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Gewichtung nach Kategorie (anpassbar)\n",
    "CATEGORY_WEIGHTS = {\n",
    "    \"company\": 1.4,\n",
    "    \"policy\": 1.2,\n",
    "    \"macro\": 1.1,\n",
    "    \"geo\": 1.0,\n",
    "    \"social\": 0.6,\n",
    "    \"other\": 0.5\n",
    "}\n",
    "\n",
    "def category_multiplier(categories):\n",
    "    if not isinstance(categories, str):\n",
    "        return 1.0\n",
    "    try:\n",
    "        cats = eval(categories) if (categories.startswith(\"[\") or categories.startswith(\"(\")) else categories\n",
    "    except Exception:\n",
    "        cats = categories\n",
    "    # ensure list\n",
    "    if isinstance(cats, str):\n",
    "        cats = [cats]\n",
    "    mult = 1.0\n",
    "    for c in cats:\n",
    "        c = str(c).strip().lower()\n",
    "        if c in CATEGORY_WEIGHTS:\n",
    "            mult = max(mult, CATEGORY_WEIGHTS[c])\n",
    "    return mult\n",
    "\n",
    "# compute base priority score\n",
    "df[\"relevance_score\"] = df[\"relevance_score\"].fillna(0.0)\n",
    "df[\"cat_multiplier\"] = df[\"categories\"].apply(lambda x: category_multiplier(str(x) if pd.notna(x) else \"\"))\n",
    "df[\"priority_raw\"] = df[\"relevance_score\"] * df[\"cat_multiplier\"]\n"
   ],
   "id": "d1f6291416b2ce01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T17:36:00.874520Z",
     "start_time": "2025-11-30T17:35:56.220732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Lade 30-Tage-Volatilität pro Ticker als Adjustment\n",
    "def fetch_volatility(ticker, days=30):\n",
    "    try:\n",
    "        df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n",
    "        if df_px.empty:\n",
    "            return 1.0\n",
    "        ret = df_px[\"Close\"].pct_change().dropna()\n",
    "        vol = ret.std()  # daily vol\n",
    "        return vol\n",
    "    except Exception:\n",
    "        return 1.0\n",
    "\n",
    "# Only fetch for unique tickers present (be careful with API limits)\n",
    "tickers = sorted({t for t in df[\"ticker\"].dropna().unique()})\n",
    "vol_map = {}\n",
    "for t in tickers:\n",
    "    vol_map[t] = fetch_volatility(t)\n",
    "vol_map\n"
   ],
   "id": "bfc86cede296df3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanac\\AppData\\Local\\Temp\\ipykernel_10528\\4064617443.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n",
      "C:\\Users\\hanac\\AppData\\Local\\Temp\\ipykernel_10528\\4064617443.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n",
      "C:\\Users\\hanac\\AppData\\Local\\Temp\\ipykernel_10528\\4064617443.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n",
      "C:\\Users\\hanac\\AppData\\Local\\Temp\\ipykernel_10528\\4064617443.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n",
      "C:\\Users\\hanac\\AppData\\Local\\Temp\\ipykernel_10528\\4064617443.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_px = yf.download(ticker, period=f\"{days}d\", interval=\"1d\", progress=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AMZN': Ticker\n",
       " AMZN    0.026903\n",
       " dtype: float64,\n",
       " 'ASML': Ticker\n",
       " ASML    0.02163\n",
       " dtype: float64,\n",
       " 'META': Ticker\n",
       " META    0.026779\n",
       " dtype: float64,\n",
       " 'NVDA': Ticker\n",
       " NVDA    0.026341\n",
       " dtype: float64,\n",
       " 'TSLA': Ticker\n",
       " TSLA    0.031592\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T17:36:01.251991Z",
     "start_time": "2025-11-30T17:36:00.972952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# normalize vol (higher vol -> higher multiplier)\n",
    "vol_values = np.array(list(vol_map.values())) if vol_map else np.array([1.0])\n",
    "if vol_map:\n",
    "    vmin, vmax = vol_values.min(), vol_values.max()\n",
    "else:\n",
    "    vmin, vmax = 1.0, 1.0\n",
    "\n",
    "def vol_multiplier_for_ticker(t):\n",
    "    if not t or t not in vol_map:\n",
    "        return 1.0\n",
    "    v = vol_map.get(t, 1.0)\n",
    "    if vmax == vmin:\n",
    "        return 1.0\n",
    "    # map vol to 0.9..1.3\n",
    "    return 0.9 + ( (v - vmin) / (vmax - vmin) ) * (1.3 - 0.9)\n",
    "\n",
    "df[\"vol_multiplier\"] = df[\"ticker\"].apply(lambda t: vol_multiplier_for_ticker(t))\n",
    "# final priority\n",
    "df[\"priority_score\"] = df[\"priority_raw\"] * df[\"vol_multiplier\"]\n",
    "\n",
    "\n",
    "# sort and save\n",
    "# sort and save to /03 (ersetzt)\n",
    "df_sorted = df.sort_values(\"priority_score\", ascending=False)\n",
    "\n",
    "out_path_prior = os.path.join(OUT_DIR_03, \"prioritized_news.csv\")\n",
    "df_sorted.to_csv(out_path_prior, index=False)\n",
    "print(\"Saved:\", os.path.abspath(out_path_prior))\n",
    "\n",
    "# filtered_out aus den eval-Daten ebenfalls im /03-Ordner speichern\n",
    "out_filtered_03 = os.path.join(OUT_DIR_03, \"filtered_out_03.csv\")\n",
    "filtered_out = df_sorted[df_sorted.get(\"relevant\")==False] if \"relevant\" in df_sorted.columns else pd.DataFrame()\n",
    "if not filtered_out.empty:\n",
    "    filtered_out.to_csv(out_filtered_03, index=False)\n",
    "    print(\"Filtered out count:\", len(filtered_out), \"Saved:\", os.path.abspath(out_filtered_03))\n",
    "else:\n",
    "    print(\"Keine gefilterten Artikel zum Speichern in /03.\")\n"
   ],
   "id": "7cb7f8d7f69a5ae5",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column vol_multiplier",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_10528\\3131930356.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     13\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m1.0\u001B[39m\n\u001B[32m     14\u001B[39m     \u001B[38;5;66;03m# map vol to 0.9..1.3\u001B[39;00m\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m0.9\u001B[39m + ( (v - vmin) / (vmax - vmin) ) * (\u001B[32m1.3\u001B[39m - \u001B[32m0.9\u001B[39m)\n\u001B[32m     16\u001B[39m \n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m df[\u001B[33m\"vol_multiplier\"\u001B[39m] = df[\u001B[33m\"ticker\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: vol_multiplier_for_ticker(t))\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# final priority\u001B[39;00m\n\u001B[32m     19\u001B[39m df[\u001B[33m\"priority_score\"\u001B[39m] = df[\u001B[33m\"priority_raw\"\u001B[39m] * df[\u001B[33m\"vol_multiplier\"\u001B[39m]\n\u001B[32m     20\u001B[39m \n",
      "\u001B[32m~\\Documents\\Agentic Artificial Intelligence\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   4308\u001B[39m             self._setitem_frame(key, value)\n\u001B[32m   4309\u001B[39m         \u001B[38;5;28;01melif\u001B[39;00m isinstance(key, (Series, np.ndarray, list, Index)):\n\u001B[32m   4310\u001B[39m             self._setitem_array(key, value)\n\u001B[32m   4311\u001B[39m         \u001B[38;5;28;01melif\u001B[39;00m isinstance(value, DataFrame):\n\u001B[32m-> \u001B[39m\u001B[32m4312\u001B[39m             self._set_item_frame_value(key, value)\n\u001B[32m   4313\u001B[39m         elif (\n\u001B[32m   4314\u001B[39m             is_list_like(value)\n\u001B[32m   4315\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m self.columns.is_unique\n",
      "\u001B[32m~\\Documents\\Agentic Artificial Intelligence\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   4466\u001B[39m \n\u001B[32m   4467\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self.isetitem(locs, value)\n\u001B[32m   4468\u001B[39m \n\u001B[32m   4469\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m len(value.columns) > \u001B[32m1\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m4470\u001B[39m             raise ValueError(\n\u001B[32m   4471\u001B[39m                 \u001B[33m\"Cannot set a DataFrame with multiple columns to the single \"\u001B[39m\n\u001B[32m   4472\u001B[39m                 f\"column {key}\"\n\u001B[32m   4473\u001B[39m             )\n",
      "\u001B[31mValueError\u001B[39m: Cannot set a DataFrame with multiple columns to the single column vol_multiplier"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Relevante Top N\n",
    "TOP_N = 50\n",
    "display(df_sorted.head(TOP_N)[[\"title\",\"ticker\",\"relevance_score\",\"categories\",\"priority_score\",\"explanation\"]])\n",
    "\n",
    "# Welche wurden ausgesondert (relevant False)\n",
    "filtered_out = df_sorted[df_sorted[\"relevant\"] == False]\n",
    "filtered_out.to_csv(\"Tools/data/filtered_out.csv\", index=False)\n",
    "print(\"Filtered out count:\", len(filtered_out), \"Saved: Tools/data/filtered_out.csv\")\n"
   ],
   "id": "50d537f4df129a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Anpassung: Du kannst CATEGORY_WEIGHTS anpassen.\n",
    "- Optional: Für kritische Entscheidungen rufe Gemini erneut an, um für die Top-Kandidaten eine präzisere Impact-Schätzung (z.B. erwartete %-Bewegung in 1-5 Tagen) zu erhalten.\n",
    "- Teste zuerst mit einer kleinen Menge, bevor du Full-Runs machst (API-Kosten).\n"
   ],
   "id": "22ba8edd77bc3361"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
